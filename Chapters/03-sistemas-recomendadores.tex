\chapter{Sistemas Recomendadores} \label{chapter:recomendadores}

%A popularização de recursos computacionais e do acesso à Internet nas
%últimas décadas proporcionou um aumento expressivo na diversidade de serviços e
%conteúdo à disposição dos usuários. Um dos fatores para este aumento é que
%os usuários, que anteriormente eram considerados meros consumidores,
%apresentam-se atualmente como produtores de conteúdo. \cite{Castells:06} analisa
%este fenômeno e afirma que a maioria da população acredita que pode influenciar
%outras pessoas atuando no mundo através da sua força de vontade e
%utilizando seus próprios meios. Isto pode ser observado no surgimento e
%proliferação de serviços criados e mantidos pelos usuários: blogs, enciclopédias
%colaborativas, como a Wikipedia\footnote{\url{http://wikipedia.org}},
%repositórios para compartilhamento de fotografia e vídeo, como Flickr
%\footnote{\url{http://flickr.com}} e Youtube\footnote{\url{http://youtube.com}},
%entre outros. Considerando a produção em termos de software, observa-se o
%exemplo das comunidades de software livre e/ou de código aberto
%(FOSS\footnote{Termo consolidado no idioma inglês, acrônimo para
%\textit{Free/Open-Source Software}, que diz respeito aos programas licenciados
%livremente para garantir aos usuários o direito de uso, estudo e modificação,
%por meio da disponibilidade do seu código-fonte.}), que propiciam a construção
%coletiva de uma ampla gama de softwares de qualidade em constante atualização
%e evolução, organizados na forma de um rossio \cite{Simon:08}.

Segundo \cite{Resnick:97}, os sistemas de recomendação aumentam a capacidade e
eficácia de um processo de indicação bastante popular nas relações sociais.
Existem recomendações produzidas exclusivamente por especialistas, a exemplo de
indicações de filmes publicadas nos principais jornais e revistas do país por
críticos de arte. Nos últimos anos, porém, a opinião e o comportamento de
usuários não especializados passaram a ser considerados nas recomendações, por
agregarem valor às mesmas. O que acontece de forma explícita, quando o
próprio usuário escreve sua opinião ou avalia a qualidade de um item, ou
implícita, quando suas preferências, comportamentos e transações são analisados
e incorporados à recomendação de forma transparente ao usuário.

O problema da recomendação é comumente formalizado através de uma estrutura de
pontuação como representação computacional da utilidade dos itens para os
usuários ou clientes. A partir de avaliações feitas pelos próprios usuários do
sistema, tenta-se estimar pontuações para os itens que ainda não foram
avaliados pelos mesmos. Uma vez que esta estimativa tenha sido feita, pode-se
recomendar os itens com maior pontuação estimada.

O conceito de utilidade, porém, é subjetivo e arduamente mensurável devido às
dificuldades em distinguir qualitativamente e definir quantitativamente os
fatores que a determinam. Portanto, com a ressalva de que estas medidas não
representam necessariamente a realidade, as pontuações são usadas como
aproximações, pois têm como base as avaliações registradas pelos próprios usuários.

\section{Ações} \label{sec:acoes}

Sistemas de recomendação são implementados nos mais diversos contextos
e podem ser projetados com finalidades distintas. Abaixo estão descritas
algumas ações relacionadas a estes sistemas identificadas por
\cite{Herlocker:04}.

\begin{description}

\item[Anotação em contexto.] Os primeiros sistemas de recomendação eram
  utilizados num cenário de informação estruturada (mensagens classificadas
  num contexto), e auxiliavam os usuários a selecionarem as mensagens a serem
  lidas dentro de cada contexto.

\item[Encontrar itens relevantes.] O sistema sugere itens para o usuário
  através de uma lista ordenada de forma decrescente, de acordo com a
  probabilidade do item ser considerado relevante pelo usuário. Esta é a ação
  mais comum entre os sistemas de recomendação comerciais, atraindo grande
  parte das pesquisas relacionadas com o tema.

\item[Encontrar todos os itens relevantes.] Em situações em que não se deseja
  ignorar nenhum item relevante, ao invés da recomendação de apenas alguns,
  todos os itens considerados relevantes devem ser retornados.

\item[Sequência recomendada.] Quando não somente os itens recomendados importa,
  mas também a ordem em que eles são apresentados, caracteriza-se a ação de
  recomendação de sequência.

\item[Expressão de opinião.] A recomendação em si muitas vezes não é o que
  atrai usuários desses sistemas. Alguns estão interessados simplesmente em
  emitir suas opiniões. Esta ação é comum em ambientes que disponibilizam um
  espaço para os usuários registrarem seus comentários e avaliações sobre os
  produtos.

\item[Ajudar usuários.] Alguns usuários utilizam sistemas de recomendação
  por acreditarem que a comunidade se beneficia da sua contribuição. Apesar de
  nem sempre aparecerem juntas, tal atividade está comumente relacionada com a
  expressão de opinião.

\item[Navegação.] Alguns usuários utilizam recomendadores mesmo quando não têm
  planos de consumir produto algum, apenas para navegar entre os itens
  disponíveis. Neste caso, aspectos como a interface, facilidade de uso e
  natureza da informação provida são de extrema importância.

\end{description}

\section{Desafios}

O desenvolvimento de sistemas recomendadores têm como desafios questões
inerentes ao problema de recomendação e sua representação computacional. As
estratégias e técnicas propostas devem levar em conta tais questões e tentar
contorná-las na medida do possível. Alguns destas questões foram apontadas
por \cite{Vozalis:03} e são citadas a seguir.

\begin{description}

  \item[Qualidade das recomendações.] Usuários esperam recomendações nas
    quais eles possam confiar. Esta confiabilidade é alcançada na medida em
    que se diminui a incidência de falsos positivos, em outras palavras,
    recomendações que não interessam ao usuário;

  \item[Esparsidade.] A existência de poucas relações usuário-item resulta
     numa matriz de relacionamentos esparsa, o que dificulta a localização de
     usuários com preferências semelhantes (relações de vizinhança) e
     resulta em recomendações fracas.

  \item[Escalabilidade.] A complexidade do cálculo de recomendações cresce
    tanto com o número de clientes quanto com a quantidade de itens,
    portanto a escalabilidade dos algoritmos é um ponto importante a ser
    considerado.

  \item[Transitividade de vizinhança.] Usuários que têm comportamento
    semelhante a um determinado usuário não necessariamente têm
    comportamento semelhante entre si. A captura deste tipo de relação pode ser
    desejável mas em geral esta informação não é resguardada, exigindo a
    aplicação de métodos específicos para tal.

  \item[Sinônimos.] Quando o universo de itens possibilita a existência
    de sinônimos, a solução deve levar esta informação em conta para prover
    melhores resultados.

  \item[Primeira avaliação.] Um item só pode ser recomendado se ele tiver sido
    escolhido por um usuário anteriormente. Portanto, novos itens precisam ter
    um tratamento especial até que sua presença seja ``notada''.

  \item[Usuário incomum.] Indivíduos com opiniões que fogem do usual, que não
    concordam nem discordam consistentemente com nenhum grupo, normalmente não
    se beneficiam de sistemas de recomendações.

\end{description}

%FIXME [Desenvolver os temas: perfis de usuario e privacidade]

%\subsection{Perfis de Usuário}
%. Identidade\\
%. Geração e manutenção de perfil\\
%. Reputação
%
%\subsection{Privacidade}

%FIXME [Analisar complexidade de cada tecnica]
%FIXME [Produzir figuras ilustrativas do naive bayes]
\subsection{Técnicas} \label{sec:tecnicas}

O desenvolvimento de sistemas de recomendação tem suas raízes em áreas
distintas e o problema computacional a ser tratado está fortemente relacionado
com outros problemas clássicos, como classificação e recuperação de informação
em documentos de texto.

A fim de obter a informação desejada, o usuário de uma ferramenta de busca
deve traduzir suas necessidades de informação para uma consulta
(\textit{query}, em inglês), que geralmente é representada por um conjunto de
\textit{palavras-chave}. O desafio do buscador é recuperar os documentos da
coleção que são relevantes para a consulta, baseando-se nos termos que a
constituem.  Ademais, visto que a busca pode retornar um número excessivo de
documentos, é desejável que este resultado seja apresentado ao usuário em ordem
decrescente de relevância, aumentando assim as chances de a informação desejada
ser encontrada com rapidez. Para tanto, cada documento da coleção deve ter uma
pontuação (peso) que indique seu grau de importância para a referida
\textit{query}. Traçando um paralelo com o problema de recomendação, a
identidade e/ou o comportamento do usuário representaria a consulta ao sistema
de busca, que provocaria o retorno dos itens de maior peso, ou seja, com maior
potencial de aceitação pelo usuário.

Na busca por informação, assume-se que as necessidades do usuário são
particulares e passageiras, e por isso a reincidência de \textit{queries} não é
muito frequente \cite{Manning:09}. Porém, em situações onde se observa que as
mesmas consultas são aplicadas com uma certa frequência, é interessante que o
sistema suporte consultas permanentes. Desta forma a computação necessária pode
ser realizada previamente e apresentada sempre que a consulta for requisitada.
Se a classe de documentos que satisfazem a uma dessas \textit{queries}
permanentes é tida como uma categoria, o processo de realização das consultas
prévias pode ser caracterizado como uma classificação. O problema da
classificação diz respeito à determinação de relacionamentos entre um dado
objeto e um conjunto de classes pré-definidas.

A recomendação pode ser vista como uma classificação, na qual os itens são
categorizados entre duas classes: relevantes e irrelevantes -- os relevantes
seriam recomendados. Porém, a definição de consultas ou regras fixas para uma
busca não é uma estratégia eficiente neste caso, porque a consulta estaria
diretamente relacionada com a identidade do usuário e portanto deveria ser
escrita especialmente para ele.

Todavia, a disciplina de inteligência artificial aborda a questão da
classificação através de estratégias que não se baseiam em busca. Algoritmos
de aprendizado de máquina são utilizados para a construção de modelos de
classificação ``inteligentes'', que ``aprendem'' através da análise de
exemplos. Os métodos supervisionados fundamentam-se na construção de um
classificador que aprende na medida em que lhe são apontados exemplos de
objetos classificados. São caracterizados como supervisionados porque as
classes atribuídas aos objetos de treinamento são determinadas por um ser
humano, que atua como um supervisor orientando o processo de aprendizado
\cite{Manning:09}. Por outro lado, algoritmos não supervisionados procuram
identificar padrões de organização nos dados sem que haja uma classificação
prévia dos exemplos.

A seguir são apresentadas algumas técnicas para tratamento destes problemas
que também são utilizadas na construção de sistemas de recomendação, dando
suporte às estratégias apresentadas na seção \ref{sec:estrategias}.

\subsubsection{K-NN} \label{sec:knn}

\textit{K-nearest neighbors (k-NN)}, em português \textit{k vizinhos mais
próximos}, é mais um algoritmo de aprendizado supervisionado para
classificação. Este método baseia-se no conceito de vizinhança, que representa
um conjunto de objetos que estão próximos no espaço de busca.

O \textit{K-NN} não exige nenhum treinamento prévio com os dados de exemplo,
que podem ser diretamente armazenados como vetores de atributos acompanhados
por suas devidas classes. A classificação de um novo objeto parte do cálculo da
vizinhança do mesmo, que é composta por $k$ objetos.

A determinação da vizinhança está diretamente relacionada com o conceito de
proximidade entre objetos, que pode ser expressa em termos de similaridade ou
de distância entre os mesmos (quanto maior a distância, menor a similaridade).
Existem diversas medidas para mensurar estes conceitos, deve-se adotar a
métrica que melhor se adeque ao domínio da aplicação e conjunto de dados.
A tabela \ref{tab:knn_distancia} apresenta algumas dessas medidas, onde os
objetos $X$ e $Y$ são representados por seus vetores $\vec{X} = (x_1,...,x_n)$
e $\vec{Y} = (y_1,...,y_n)$. A similaridade de cosseno mede a similaridade de
dois vetores através do cosseno do ângulo entre os mesmos. O coeficiente de
\textit{Pearson} é equivalente ao cosseno do ângulo entre os vetores
centralizados na média. E o coeficiente de \textit{Tanimoto} é uma extensão da
similaridade de cossenos que resulta no índice de \textit{Jaccard} para
atributos binários.

\begin{table}[h!]
  \caption{K-NN: Medidas de distância e similaridade entre objetos}
  \label{tab:knn_distancia}
  \centering
  \newcommand\T{\rule{0pt}{2.8ex}}
  \newcommand\B{\rule[-1.8ex]{0pt}{0pt}}
  \begin{tabular}{| l | l |}
    \hline
    Distância euclidiana &
    \T\B$\mathid{D}(X,Y) = \sqrt{(x_1-y_1)^2+(x_2-y_2)^2+...+(x_n-y_n)^2}$\\
    \hline
    Similaridade de cosseno &
    $\mathid{sim}(X,Y) = \frac{\T\vec{X} \cdot \vec{Y}}{|\vec{X}| |\vec{Y}|}
                       = \frac{\textstyle \sum_{1\leq i \leq n} x_i y_i}
                              {\textstyle \sqrt{\sum_{1\leq i \leq n} x_i^2}
                               \sqrt{\sum_{1\leq i \leq n} y_i^2}\B}$\\
    \hline
    Coeficiente de \textit{Pearson} &
    $\mathid{P}(X,Y) = \frac{\T\textstyle\sum_{1 \leq i \leq n} (x_i-\bar{x})
                                     (y_i-\bar{y})}
                   {\textstyle\sqrt{\sum_{1 \leq i \leq n} (x_i-\bar{x})^2}
                    \sqrt{\sum_{1 \leq i \leq n} (y_i-\bar{y})^2}\B}$\\
    \hline
    Coeficiente de \textit{Tanimoto} &
    $\mathid{T}(X,Y) = \frac{\T\textstyle\vec{X} \cdot \vec{Y}}
                            {\textstyle |\vec{X}|^2 + |\vec{Y}|^2 -
                             \vec{X} \cdot \vec{Y}}$\\
    \hline
  \end{tabular}
\end{table}

Após a definição de vizinhança, a classe mais frequente entre seus $k$ vizinhos
é atribuída ao novo objeto. Desta forma, a similaridade também pode ser
entendida como grau de influência entre os objetos. Os objetos mais semelhantes
a um novo objeto terão maior influência no cálculo de sua classificação.

\newpage
%\vspace{0.3cm}
\hspace{-1.4cm}
\textbf{Seleção de atributos} \label{sec:selecao_atributos}

Uma grande quantidade de atributos a ser considerada resulta em alta
complexidade computacional, além de geralmente mascarar a presença de ruídos
(dados que prejudicam a acurácia da classificação quando considerados).
A fim de amenizar este problema, é comum a realização de um processo denominado
seleção de atributos, que consiste em escolher alguns atributos dos dados e
utilizar apenas estes como conjunto de treinamento para a classificação. Esta
seleção equivale à substituição de um classificador complexo por um mais
simples. \cite{Manning:09} defende que, especialmente quando a quantidade de
dados de treinamento é limitada, modelos mais fracos são preferíveis.

A seleção de atributos geralmente é realizada para cada classe em separado,
seguida pela combinação dos diversos conjuntos. Abaixo são apresentados alguns
métodos de escolha.

\begin{description}

  \item[Informação mútua.] Análise de quanto a presença ou ausência de um
    atributo contribui para a tomada de decisão correta por uma determinada
    classe. Informação mútua máxima significa que o atributo é um indicador
    perfeito para pertencimento a uma classe. Isto acontece quando um objeto
    apresenta o atributo se e somente se o objeto pertence à classe;

  \item[Independência de eventos.] Aplicação do teste estatístico $\chi^2$ para
    avaliar a independência de dois eventos -- neste caso, um atributo e uma
    classe. Se os dois eventos são dependentes, então a ocorrência do atributo
    torna a ocorrência da classe mais provável.

  \item[Baseado em frequência.] Seleção dos atributos mais comuns para uma
    classe.

\end{description}

Os métodos apresentados acima são ``gulosos'', ou seja, assumem escolhas ótimas
locais na esperança de serem ótimas globais. Como resultado, podem selecionar
atributos que não acrescentam nenhuma informação para a classificação quando
considerados outros previamente escolhidos. Apesar disto, algoritmos não
gulosos são raramente utilizados devido a seu custo computacional
\cite{Manning:09}.

\subsection{Classificador bayesiano}

\textit{Bayes ingênuo} é uma solução para classificação que figura entre os
algoritmos de aprendizado de máquina supervisionados. O classificador apoia-se
num modelo probabilístico que aplica o teorema de Bayes com fortes suposições
de independência de atributos -- por esta razão o método é considerado ingênuo.
Em outras palavras, a presença ou ausência de um atributo em um objeto de uma
classe não estaria relacionada com a incidência de nenhum outro atributo.

A decisão acerca da classe a qual um objeto pertence é tomada de acordo com o
modelo de probabilidade máxima posterior \textit{(MAP)}, indicada na equação
\ref{eq:map}. Dado que $C$ é o conjunto de classes e $x$ objeto a ser
classificado, a classe atribuída a este será a que apresentar maior
probabilidade condicionada a $x$. $\hat{P}$ é utilizado ao invés de $P$ porque
geralmente não se sabe o valor exato das probabilidades, que são estimadas a
partir dos dados de treinamento.

\begin{equation}
\label{eq:map}
  \mathid{c_{MAP}} = \underset{c \in C}{\operatorname{arg\ max}} \ \hat{P}(c|x)
\end{equation}

A equação \ref{eq:bayes} aplica o Teorema de Bayes para probabilidades
condicionadas. Na prática, apenas o numerador da fração interessa, visto que o
denominador é constante para todas as classes, portanto não afeta o
$\operatorname{arg\ max}$ (equação \ref{eq:bayes_no_deno}).

\begin{eqnarray}
\label{eq:bayes}
  \mathid{c_{MAP}} & = & \underset{c \in C}{\operatorname{arg\ max}} \
                         \frac{\hat{P}(x|c) \hat{P}(c)}{\cancel{\hat{P}(x)}} \\
                {} & {} & {} \nonumber \\
\label{eq:bayes_no_deno}
                   & = & \underset{c \in C}{\operatorname{arg\ max}} \
                         \hat{P}(x|c) \hat{P}(c)
\end{eqnarray}

É neste ponto que a independência de atributos é importante. Considera-se que
um documento $x$ pode ser caracterizado por uma série de atributos $x_i$ -- no
caso de documentos de texto, os atributos são os próprios termos. Assumindo que
a ocorrência de atributos acontece independentemente, tem-se que:

\begin{equation}
\label{eq:independencia}
  \hat{P}(x|c) = \hat{P}(x_1,x_2,...,x_n|c)
               = \hat{P}(x_1|c) \hat{P}(x_2|c)\ ...\ \hat{P}(x_n|c)
\end{equation}

Portanto, a função de decisão pode ser reescrita através da equação
\ref{eq:bayes_prod}. Cada parâmetro condicional $\hat{P}(x_i|c)$ é um peso
que representa a qualidade do atributo $x_i$ como indicador da classe $c$,
enquanto que $\hat{P}(c)$ é a frequência relativa da classe $c$.

\begin{equation}
\label{eq:bayes_prod}
  \mathid{c_{MAP}} = \underset{c \in C}{\operatorname{arg\ max}} \ \
                     \hat{P}(c) \prod_{1 \le i \le n} \hat{P}(x_i|c)
\end{equation}

Os parâmetros são obtidos através da estimativa de maior probabilidade
\textit{(MLE)}, que corresponde ao valor mais provável de cada parâmetro de
acordo com os dados de treinamento. A equação \ref{eq:p_c} traz a estimativa de
$\hat{P}(c)$, onde $N_c$ é o número de objetos da classe $c$ e $N$ é o número
total de documentos.

\begin{equation}
\label{eq:p_c}
  \hat{P}(c) = \frac{N_c}{N}
\end{equation}

As probabilidades condicionais são estimadas como a frequência relativa do
atributo $x$ em objetos que pertencem à classe $c$. Na equação \ref{eq:p_xc},
$T_{\mathit{cx}}$ é o número de ocorrências de $x$ em objetos de exemplo da
classe $c$ e $V$ é o conjunto de atributos que os objetos podem apresentar.

\begin{equation}
\label{eq:p_xc}
  \hat{P}(x|c) = \frac{T_{\mathit{cx}}}
                      {\displaystyle \sum_{x' \in V} T_{\mathit{cx}'}}
\end{equation}

No entanto, a estimativa \textit{MLE} é zero para combinações atributo-classe
que não ocorrem nos dados de treinamento. Considerando que as probabilidades
condicionais de todos os atributos serão multiplicadas (equação
\ref{eq:bayes_prod}), a simples ocorrência de uma probabilidade zerada resulta
na desconsideração da classe na referida classificação. E de fato, dados de
treinamento nunca são abrangentes o suficiente para representar a frequência de
eventos raros de forma adequada \cite{Manning:09}. Para eliminar
$\mathit{zeros}$, adiciona-se $1$ a cada termo da equação \ref{eq:p_xc}:

\begin{equation}
\label{eq:p_xc+1}
  \hat{P}(x|c) = \frac{T_{\mathit{cx}}+1}
                      {\displaystyle \sum_{x' \in V} T_{\mathit{cx}'}+1}
\end{equation}

O classificador bayesiano também é sensível a ruídos, logo, sua performance é
igualmente beneficiada pelo processo de seleção de atributos descrito na seção
\ref{sec:selecao_atributos}.

Apesar de a independência de atributos não ser verificada para a maioria
dos domínios de aplicação, na prática o Bayes ingênuo apresenta resultados
satisfatórios. \cite{Zhang:04} atribui a surpreendente boa performance deste
método ao fato de que a mera existência de dependências entre atributos não
prejudicaria a classificação, mas sim o modo como as dependências estão
distribuídas ao longo das classes. Segundo o autor, desde que as dependências
estejam distribuídas igualmente nas classes, não há problema em haver
dependência forte entre dois atributos.

\vspace{0.3cm} \hspace{-1.4cm}
\textbf{Variantes do modelo Bayes ingênuo}

As duas principais variantes de implementação do classificador bayesiano,
denominadas de modelo \textit{multinomial} e de \textit{Bernoulli}, diferem
fundamentalmente na maneira como os objetos são representados.

O primeiro modelo utiliza uma representação que considera informações espaciais
sobre o objeto. Na classificação de documentos de texto, por exemplo, o modelo
gera um atributo para cada posição do documento, que corresponde a um termo do
vocabulário. Já o modelo de \textit{Bernoulli} produz um indicador de
presença ou ausência para cada possível atributo (no caso de texto, cada termo
do vocabulário).

A escolha da representação de documentos adequada é uma decisão crítica no
projeto de um classificador, visto que o próprio significado de um atributo
depende da representação. No \textit{multinomial}, um atributo pode assumir
como valor qualquer termo do vocabulário, o que resulta numa representação do
documento correspondente à sequência de termos do mesmo. Já para o modelo de
\textit{Bernoulli}, um atributo pode assumir apenas os valores $0$ e $1$, e a
representação do documento é uma sequência de $0$s e $1$s do tamanho do
vocabulário.

%A figura \ref{fig:exemplo_bayes} ilustra as peculiaridades de cada
%representação.
%
%\begin{figure}[ht]
%\centering
%\begin{tabular}{*4{c}}
%\begin{overpic}[width=2.3cm]{fig/doc_background.png}\put(60,5){\scriptsize (1)}
%  \put(5,44){\parbox{1.8cm}{\scriptsize Por motivo \\ de segurança, \\
%    comunicamos a todos os clientes que atualizem sua senha por email.}}
%    \end{overpic} &
%\begin{overpic}[width=2.3cm]{fig/doc_background.png}\put(60,5){\scriptsize (2)}
%  \put(5,44){\parbox{1.8cm}{\scriptsize Atualização \\ urgente de \\  senha.
%    \\ \\ Clique aqui.}}\end{overpic} &
%\begin{overpic}[width=2.3cm]{fig/doc_background.png}\put(60,5){\scriptsize (3)}
%  \put(5,44){\parbox{1.8cm}{\scriptsize Você foi \\ sorteado e \\ acaba de
%    ganhar 1 milhão de reais. Clique aqui e saiba como resgatar seu prêmio.}}
%    \end{overpic} &
%\begin{overpic}[width=2.3cm]{fig/doc_background.png}\put(60,5){\scriptsize (4)}
%  \put(5,44){\parbox{1.8cm}{\scriptsize Perca peso fácil e de forma divertida.
%    Pare de sofrer!}}\end{overpic} \\
%\begin{overpic}[width=2.3cm]{fig/doc_background.png}\put(60,5){\scriptsize (5)}
%  \put(5,44){\parbox{1.8cm}{\scriptsize Emagreça 10kg em duas semanas! Clique
%    aqui e descubra como.}}\end{overpic} &
%\begin{overpic}[width=2.3cm]{fig/doc_background.png}\put(60,5){\scriptsize (6)}
%  \put(5,44){\parbox{1.8cm}{\scriptsize Compre viagra com 69\% de desconto!}}
%    \end{overpic} &
%\begin{overpic}[width=2.3cm]{fig/doc_background.png}\put(60,5){\scriptsize (7)}
%  \put(5,44){\parbox{1.8cm}{\scriptsize Se você não pode mudar sua vida, mude
%    pelo menos a sua bolsa!}}\end{overpic} &
%\begin{overpic}[width=2.3cm]{fig/doc_background.png}\put(60,5){\scriptsize (8)}
%  \put(5,44){\parbox{1.8cm}{\scriptsize Aprenda a investir na bolsa em uma
%    semana.}}\end{overpic}
%\end{tabular}
%\caption{Coleção de documentos classificados em \textit{spam} e \textit{não-spam}}
%\label{fig:colecao_spam}
%\end{figure}

\subsection{Medida $\boldsymbol{\tfidf}$}

Acrônimo para \textit{term frequency - inverse document frequency}, $\tfidf$ é
uma medida de peso clássica utilizada em ferramentas de busca em texto para
ordenação do resultado da consulta pela relevância dos documentos.

O universo da busca é uma coleção de documentos de texto. Um documento por sua
vez é uma coleção de palavras, geralmente referenciadas como \textit{termos do
documento}. O conjunto de todas as palavras presentes nos documentos da
coleção é denominado \textit{dicionário} ou \textit{vocabulário}. Desta forma,
um documento $d$ composto por $n$ termos do vocabulário $V$ pode ser
representado como $d = \{t_1, t_2, ..., t_n | 1 \leq i \leq n, t_i \in V\}$.

Contudo, alguns termos do vocabulário, designados como \textit{stop words}, são
normalmente desconsiderados no cálculo de relevância dos documentos por serem
muito frequentes na coleção e, em decorrência disto, pouco informativos acerca
do teor dos textos. Artigos e pronomes, por exemplo, geralmente figuram nesta
categoria.

Outra consideração acerca da representação dos documentos como conjuntos de
termos é a realização de normalizações morfológicas. Diferentes palavras que
dizem respeito ao mesmo conceito podem ser utilizadas ao longo de uma coleção,
por exemplo, os termos \textit{casa}, \textit{casinha} e \textit{casas}. Em
certos contextos, deseja-se que a busca por uma determinada variante retorne
ocorrências de todas as outras possibilidades. Neste caso, os termos devem ser
tratados em sua forma normalizada, eliminando variações como plurais e flexões
verbais. Os processos mais comuns de normalização são: \textit{stemming}, que
reduz a palavra ao seu radical; e \textit{lematização}, que reduz a palavra à
sua forma canônica (por exemplo, verbos no infinitivo, substantivos no singular
masculino etc). A figura \ref{fig:normalizacao} apresenta um documento de texto
numa coleção hipotética\footnote{Os textos utilizados nos exemplos desta seção
são excertos de letras de música de diversos compositores brasileiros.} e a sua
representação após eliminação de \textit{stop words} e procedimento de
\textit{stemming}.

\begin{figure}[ht]
\centering
\begin{tabular}{*3{c}}
\begin{overpic}[width=2.8cm]{Figures/doc_background.png}
  \put(12,44){\parbox{1.8cm}{\scriptsize August\sout{a}, graç\sout{as} \sout{a}
    deus, entr\sout{e} \sout{você} \sout{e} \sout{a} Angél\sout{ica},
    \sout{eu} encontr\sout{ei} \sout{a} Consol\sout{ação}, \sout{que}
    v\sout{eio} olh\sout{ar} \sout{por} \sout{mim} \sout{e} \sout{me}
    d\sout{eu} \sout{a} mão.}}\end{overpic}  &
\raisebox{1.5cm}{\Huge $\Longrightarrow$} &
\begin{overpic}[width=2.8cm]{Figures/doc_background.png}
  \put(12,44){\parbox{1.8cm}{\scriptsize august \ \ \ grac \\ deus entr angel
    encontr consol v\ \ \  olh\ \ \  d\ \ \  mão}}\end{overpic}
\end{tabular}
\caption{Eliminação de \textit{stop words} e normalização do documento por
         \textit{stemming}}
\label{fig:normalizacao}
\end{figure}

A simples presença de um termo da \textit{query} em um documento da coleção já
é um indicativo de que o mesmo tem alguma relação com a consulta. No entanto, a
quantidade de vezes que o termo ocorre é ainda mais informativo sobre sua
relação com o conteúdo do documento. Intuitivamente, os documentos que
referenciam os termos de uma \textit{query} com mais frequência estão mais
fortemente relacionados com a mesma, e por isso deveriam receber uma maior
pontuação de relevância. O peso $\tf_{t,d}$ (\textit{term frequency})
quantifica esta noção intuitiva, relacionando documentos da coleção e termos do
dicionário de acordo com a frequência destes nos documentos. Em sua abordagem
mais simples, $\tf_{t,d}$ é igual ao número de ocorrências do termo $t$ no
documento $d$.

A figura \ref{fig:colecao} ilustra uma coleção de documentos, cujos valores de
$\tf_{t,d}$ para alguns termos do dicionário são apresentados na tabela
\ref{tab:tf}. Por exemplo, a palavra \textit{morena} ocorre duas vezes
no documento $(1)$, por isso $\tf_{\mathit{moren},1} = 2$. O cálculo do
$\tf$s já considera os radicais dos termos, resultantes de um processo de
\textit{stemming}. Em razão disto, $\tf_{\mathit{olh},2} = 3$, pois tanto a
palavra \textit{olho} quanto as diferentes flexões do verbo \textit{olhar}
contribuem para a contagem de frequência do termo \textit{olh}. Na tabela
\ref{tab:tf}, os radicais dos vocábulos são seguidos por algumas variações, a
título de ilustração.

\begin{figure}[ht]
\centering
\begin{tabular}{*4{c}}
\begin{overpic}[width=2.3cm]{Figures/doc_background.png}\put(60,5){\scriptsize (1)}
  \put(5,44){\parbox{1.8cm}{\scriptsize Morena,\\ minha morena, tira a roupa da
    janela. Vendo a roupa sem a dona, eu penso na dona sem ela.}}\end{overpic} &
\begin{overpic}[width=2.3cm]{Figures/doc_background.png}\put(60,5){\scriptsize (2)}
  \put(5,44){\parbox{1.8cm}{\scriptsize Olha o \\ jeito dela, morena cor de
    canela, pode morrer de paixão quem olhar nos olhos dela.}}\end{overpic} &
\begin{overpic}[width=2.3cm]{Figures/doc_background.png}\put(60,5){\scriptsize (3)}
  \put(5,44){\parbox{1.8cm}{\scriptsize O cravo brigou com a rosa debaixo de
    uma sacada. O cravo saiu ferido.}}\end{overpic} &
\begin{overpic}[width=2.3cm]{Figures/doc_background.png}\put(60,5){\scriptsize (4)}
  \put(5,44){\parbox{1.8cm}{\scriptsize Morena dos olhos d'água, tira os seus
    olhos do mar.}}\end{overpic} \\
\begin{overpic}[width=2.3cm]{Figures/doc_background.png}\put(60,5){\scriptsize (5)}
  \put(5,44){\parbox{1.8cm}{\scriptsize Queixo-me às rosas, mas que bobagem,
    as rosas não falam.}}
    \end{overpic} &
\begin{overpic}[width=2.3cm]{Figures/doc_background.png}\put(60,5){\scriptsize (6)}
  \put(5,44){\parbox{1.8cm}{\scriptsize Morena de Angola que leva o chocalho
    amarrado na canela.}}\end{overpic} &
\begin{overpic}[width=2.3cm]{Figures/doc_background.png}\put(60,5){\scriptsize (7)}
  \put(5,44){\parbox{1.8cm}{\scriptsize Onde vais \\ morena Rosa, com essa rosa
    no cabelo e esse andar de moça prosa.}}\end{overpic} &
\begin{overpic}[width=2.3cm]{Figures/doc_background.png}\put(60,5){\scriptsize (8)}
  \put(5,44){\parbox{1.8cm}{\scriptsize A padaria Dona Morena vende pão de
    cravo e canela.}}\end{overpic}
\end{tabular}
\caption{Coleção de documentos}
\label{fig:colecao}
\end{figure}

\begin{table}[h!]
  \caption{Frequência dos termos nos documentos da coleção}
  \label{tab:tf}
  \centering
  \small
  \begin{tabular}{| l | c | c | c | c | c | c | c | c |}
    \hline
    \multicolumn{9}{|c|}{$\boldsymbol{\tf_{t,d}}$}\\
    \hline
    \backslashbox{\textbf{\textit{Termo}}}{\vspace{-0.2cm}\textbf{\textit{Doc}}}&
    \textbf{(1)}&\textbf{(2)}&\textbf{(3)}&
    \textbf{(4)}&\textbf{(5)}&\textbf{(6)}&
    \textbf{(7)}&\textbf{(8)}\\
    \hline
    moren \textit{\{a,o\}} & $2$ & $1$ & $0$ & $1$ & $0$ & $1$ & $1$ & $1$ \\
    \hline
    roup \textit{\{a,ão\}} & $2$ & $0$ & $0$ & $0$ & $0$ & $0$ & $0$ & $0$ \\
    \hline
    don \textit{\{a,o\}} & $2$ & $0$ & $0$ & $0$ & $0$ & $0$ & $0$ & $1$ \\
    \hline
    crav \textit{\{o,eiro\}} & $0$ & $0$ & $2$ & $0$ & $0$ & $0$ & $0$ & $1$ \\
    \hline
    canel \textit{\{a,eira\}} & $0$ & $1$ & $0$ & $0$ & $0$ & $1$ & $0$ & $1$ \\
    \hline
    olh \textit{\{o,ar\}} & $0$ & $3$ & $0$ & $2$ & $0$ & $0$ & $0$ & $0$ \\
    \hline
    ros \textit{\{a,eira\}} & $0$ & $0$ & $1$ & $0$ & $2$ & $0$ & $2$ & $0$ \\
    \hline
    bob \textit{\{o,agem\}} & $0$ & $0$ & $0$ & $0$ & $1$ & $0$ & $0$ & $0$ \\
    \hline
  \end{tabular}
\end{table}

O conjunto de pesos determinado pelos $\tf$s dos termos de um documento
pode ser entendido como um resumo quantitativo do mesmo. Esta visão do
documento é comumente referenciada na literatura como ``saco de palavras'',
onde a disposição das palavras é ignorada e apenas a quantidade de ocorrências
para cada termo é considerada.

Uma medida de relevância baseada simplesmente na incidência dos termos da
\textit{query} nos documentos ($\mathid{RI}$) poderia ser calculada através da
equação \ref{eq:relevancia_tf}.

\begin{equation}
\label{eq:relevancia_tf}
  \mathid{RI}_{d,q} = \sum_{t \in q} \tf_{t,d}
\end{equation}

No entanto, alguns termos têm pouco poder de discriminação na determinação
de relevância de um documento, por estarem presentes em quase todos os
documentos. Ao passo que existem outros muito raros que quando presentes
são forte indicativo de relevância. No contexto da coleção da figura
\ref{fig:colecao}, por exemplo, a \textit{query} $\{\mathit{morena, bobagem}\}$
é composta por um termo muito frequente e outro muito raro. Coincidentemente,
os documentos $(3)$ e $(5)$, contém apenas um dos dois elementos da consulta,
porém ambos apresentam $\tf_{t,d}=1$ para os respectivos termos. Todavia,
enquanto esta frequência se repete ao longo da coleção múltiplas vezes para o
termo \textit{morena}, ela é única para o termo \textit{bobagem}, o que de fato
diferencia o documento $(5)$ dos demais.

O $\idf_t$ (\textit{inverse document frequency}) foi então introduzido para
atenuar o efeito de termos muito comuns no cálculo de relevância, diminuindo o
peso relacionado a um termo por um fator que cresce com sua frequência em
documentos na coleção \cite{Manning:09}. A equação \ref{eq:idf} apresenta a
forma clássica do $\idf$, na qual $N$ representa o número de documentos da
coleção e $\df_t$ (\textit{document frequency}) é o número de documentos que
contém o termo $t$. É comum que o universo da busca seja uma coleção de
documentos de altíssima dimensão, resultando em valores de $\df_t$ muito
discrepantes. O uso do $\log$ diminui a escala de valores, permitindo que
frequências muito grandes e muito pequenas sejam comparadas sem problemas.

\begin{equation}
\label{eq:idf}
\idf_t = \log \frac{N}{\df_t}
\end{equation}

Valores de $\idf_t$ para a coleção da figura \ref{fig:colecao} são apresentados
na tabela \ref{tab:idf}. Novamente os radicais dos termos são considerados:
$\idf_\mathit{morena} = \idf_\mathit{moren} = \log \frac{8}{6} = 0.12$,
enquanto $\idf_\mathit{bobagem} = \idf_\mathit{bob} = \log \frac{8}{1} = 0.9$.

\begin{table}[h!]
  \caption{Valores de $\boldsymbol{\idf_t}$ para termos do dicionário}
  \label{tab:idf}
  \centering
  \small
  \begin{tabular}{| l | c | c | c | c | c | c | c | c |}
    \hline
    \textbf{\textit{Termo}} &
    moren & roup & don & crav & canel & olh & ros & bob\\
    \hline
    $\boldsymbol{\idf_t}$ &
    $0.12$ & $0.9$ & $0.6$ & $0.6$ & $0.42$ & $0.6$ & $0.42$ & $0.9$\\
    \hline
  \end{tabular}
\end{table}

A medida $\tfidf_{t,d}$ combina as definições de $\tf$ e $\idf$ (equação
\ref{eq:tfidf}), produzindo um peso composto com as seguintes propriedades:

\begin{enumerate}
  \item É alto quando $t$ ocorre muitas vezes em $d$ e em poucos documentos da
        coleção (ambos $\tf$ e $\idf$ são altos);
  \item Diminui quando ocorre menos vezes em $d$ ($\tf$ mais baixo) ou em
        muitos documentos da coleção ($\idf$ mais baixo);
  \item É muito baixa quando o termo ocorre em quase todos os documentos
        (mesmo para valores altos de $\tf$, para termos muito comuns o peso
        $\idf$ domina a fórmula, em decorrência do uso do $\log$).
\end{enumerate}

\begin{equation}
\label{eq:tfidf}
\tfidf_{t,d} = \tf_{t,d} \cdot \idf_t
\end{equation}

A medida de relevância apresentada na equação \ref{eq:relevancia_tf} pode ser
refinada para somar os pesos $\tfidf$ do documento $d$ com relação aos termos
da \textit{query} $q$, resultando na media $\mathid{R}_{d,q}$ apresentada na equação
\ref{eq:relevancia} \cite{Manning:09}.

\begin{equation}
\label{eq:relevancia}
\mathid{R}_{d,q} = \sum_{t \in q} \tfidf_{t,d}
\end{equation}

A tabela \ref{tab:tfidf-resultado} apresenta a ordenação dos documentos da
coleção como resultado do cálculo de relevância por $\tfidf$ para as
consultas $q_1=\{\mathit{morena}\}$, $q_2=\{\mathit{morena, bobagem}\}$ e
$q_3=\{\mathit{morena, dona, rosa}\}$. Os valores $\tfidf_{t,d}$ foram
obtidos a partir da equação \ref{eq:tfidf}, com os pesos das tabelas
\ref{tab:tf} e \ref{tab:idf}. Por exemplo, $\tfidf_{\mathit{morena,1}} =
\tf_{\mathit{morena,1}} \cdot \idf_{\mathit{morena}} = 2 \cdot 0.12 = 0.24$.

\begin{table}[h!]
  \caption{Ordenação dos documentos como resultado das consultas
           $\boldsymbol{q_1}$, $\boldsymbol{q_2}$ e $\boldsymbol{q_3}$}
  \label{tab:tfidf-resultado}
  \centering
  \footnotesize
  \begin{tabular}{| c | c | c | c | c | c | c | c | c | c | c | c | c | c |}
    \cline{1-3}\cline{5-8}\cline{10-14}
    \multirow{2}{*}{\textbf{doc}} & $\boldsymbol{q_1}$ & \multirow{2}{*}{$\boldsymbol{\mathsfsl{R}_{d,q}}$} & &
    \multirow{2}{*}{\textbf{doc}} & \multicolumn{2}{|c|}{$\boldsymbol{q_2}$} & \multirow{2}{*}{$\boldsymbol{\mathsfsl{R}_{d,q}}$} &&
    \multirow{2}{*}{\textbf{doc}} & \multicolumn{3}{|c|}{$\boldsymbol{q_3}$} & \multirow{2}{*}{$\boldsymbol{\mathsfsl{R}_{d,q}}$} \\
    \cline{2-2}\cline{6-7}\cline{11-13}
    & \textit{morena} & & & &
      \textit{morena} & \textit{bobagem} & & & &
      \textit{morena} &\textit{dona} & \textit{rosa} & \\
    \cline{1-3}\cline{5-8}\cline{10-14}
    (1) & $0.24$ & $0.24$ & &
    (5) & $0$ & $0.9$ & $0.9$ & &
    (1) & $0.24$ & $1.2$ & $0$ & $1.44$ \\
    \cline{1-3}\cline{5-8}\cline{10-14}
    (2) & $0.12$ & $0.12$ & &
    (1) & $0.24$ & $0$ & $0.24$ & &
    (8) & $0.12$ & $1.2$ & $0$ & $1.32$ \\
    \cline{1-3}\cline{5-8}\cline{10-14}
    (4) & $0.12$ & $0.12$ & &
    (2) & $0.12$ & $0$ & $0.12$ & &
    (7) & $0.12$ & $0$ & $0.84$ & $0.96$ \\
    \cline{1-3}\cline{5-8}\cline{10-14}
    (6) & $0.12$ & $0.12$ & &
    (4) & $0.12$ & $0$ & $0.12$ & &
    (5) & $0$ & $0$ & $0.84$ & $0.84$ \\
    \cline{1-3}\cline{5-8}\cline{10-14}
    (7) & $0.12$ & $0.12$ & &
    (6) & $0.12$ & $0$ & $0.12$ & &
    (3) & $0$ & $0$ & $0.42$ & $0.42$ \\
    \cline{1-3}\cline{5-8}\cline{10-14}
    (8) & $0.12$ & $0.12$ & &
    (7) & $0.12$ & $0$ & $0.12$ & &
    (2) & $0.12$ & $0$ & $0$ & $0.12$ \\
    \cline{1-3}\cline{5-8}\cline{10-14}
    (3) & $0$ & $0$ & &
    (8) & $0.12$ & $0$ & $0.12$ & &
    (4) & $0.12$ & $0$ & $0$ & $0.12$ \\
    \cline{1-3}\cline{5-8}\cline{10-14}
    (5) & $0$ & $0$ & &
    (3) & $0$ & $0$ & $0$ & &
    (6) & $0.12$ & $0$ & $0$ & $0.12$ \\
    \cline{1-3}\cline{5-8}\cline{10-14}
  \end{tabular}
\end{table}

Existem diversas variantes para o cálculo dos pesos $\tf_{t,d}$ e $\idf_t$,
propostas com o intuito de aperfeiçoar o processo de busca. Por exemplo,
geralmente a presença de uma palavra 20 vezes num documento não tem de fato
20 vezes mais representatividade do que uma ocorrência única. Documentos
distintos podem referenciar o mesmo conceito de forma concisa ou prolixa, e
simplesmente este fato não deve ser motivo para pesos muito discrepantes com
relação a uma \textit{query}, visto que o teor do texto é o mesmo. A variante
denominada \textit{$\tf$ sub-linear} incorpora o logaritmo ao cálculo do $\tf$
para atenuar o crescimento do peso para valores crescentes de frequência
(equação \ref{eq:tfsub}).

\begin{equation}
  \label{eq:tfsub}
  \mathid{tf-sub}_{t,d} =
  \begin{cases}
    1+\log \tf_{t,d} & \text{, se}\ \tf_{t,d}>0 \\
    0                & \text{, caso contrário}
  \end{cases}
\end{equation}

Outras abordagens alternativas utilizam normalizações por diversas medidas:
comprimento do documento, comprimento médio dos documentos da coleção, $\tf$
máximo ou médio entre os $\tf$s de todos os termos do documento, entre outros.

\newpage
%\vspace{0.3cm}
\hspace{-1.4cm}
\textbf{Modelo de espaço vetorial}

Uma coleção de documentos pode ser representada por um conjunto de vetores,
sendo cada documento descrito como um vetor de termos do dicionário e os
respectivos pesos $\tfidf$ do documento. Tem-se como resultado uma visão
da coleção como uma matriz de dimensões $M \times N$, na qual as linhas
representam os $M$ termos do dicionário e as colunas os $N$ documentos da
coleção. Esta representação, conhecida como \textit{modelo de espaço vetorial},
é amplamente utilizada em soluções para recuperação da informação.

Assumindo que o vocabulário se restringe apenas aos termos para os quais os
valores de $\tf$ e $\idf$ foram calculados (tabelas \ref{tab:tf} e
\ref{tab:idf}), a coleção de documentos da figura \ref{fig:colecao} pode ser
representada no modelo de espaço vetorial pela matriz da tabela
\ref{tab:colecao_mev}.

\begin{table}[h!]
  \caption{Representação da coleção no modelo de espaço vetorial}
  \label{tab:colecao_mev}
  \centering
  \small
  \begin{tabular}{| l | c | c | c | c | c | c | c | c |}
    \hline
    \multicolumn{9}{|c|}{$\boldsymbol{\tfidf_{t,d}}$}\\
    \hline
    \backslashbox{\textbf{\textit{Termo}}}
                 {\vspace{-0.2cm}\textbf{\textit{Doc}}}&
    (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8)\\
    \hline
    moren & $0.24$ & $0.12$ & $0$ & $0.12$ & $0$ & $0.12$ & $0.12$ & $0.12$ \\
    \hline
    roup & $1.8$ & $0$ & $0$ & $0$ & $0$ & $0$ & $0$ & $0$ \\
    \hline
    don & $1.2$ & $0$ & $0$ & $0$ & $0$ & $0$ & $0$ & $0.6$ \\
    \hline
    crav & $0$ & $0$ & $1.2$ & $0$ & $0$ & $0$ & $0$ & $0.6$ \\
    \hline
    canel & $0$ & $0.42$ & $0$ & $0$ & $0$ & $0.42$ & $0$ & $0.42$ \\
    \hline
    olh & $0$ & $1.8$ & $0$ & $1.2$ & $0$ & $0$ & $0$ & $0$ \\
    \hline
    ros & $0$ & $0$ & $0.42$ & $0$ & $0.84$ & $0$ & $0.84$ & $0$ \\
    \hline
    bob & $0$ & $0$ & $0$ & $0$ & $0.9$ & $0$ & $0$ & $0$ \\
    \hline
  \end{tabular}
\end{table}

%\newpage
\vspace{0.3cm}
\hspace{-1.4cm}
\textbf{Similaridade de cosseno}

Medir a similaridade entre dois documentos pode ser útil, por exemplo, para
disponibilizar o recurso ``mais do mesmo'', onde o usuário pede indicações
de itens semelhantes a um que ele já conhece. Porém, se a diferença entre os
vetores de pesos de dois documentos for usada como medida para avaliação de
similaridade entre os mesmos, pode acontecer de documentos com conteúdo similar
serem considerados diferentes simplesmente porque um é muito maior que o outro.
Para compensar o efeito do comprimento dos documentos utiliza-se como medida de
similaridade o cosseno do ângulo entre os vetores que os representam
($\theta$), apresentada na equação \ref{eq:sim-cos}. O numerador representa o
produto escalar dos dois vetores e o denominador a distância euclidiana entre
os mesmos.

\begin{equation}
\label{eq:sim-cos}
  \mathid{sim}(d_1,d_2) = \cos(\theta)
                        = \frac{\vec{V(d_1)} \cdot \vec{V(d_2)}}
                               {|\vec{V(d_1)}| |\vec{V(d_2)}|}
\end{equation}

Dado um documento $d$, para encontrar os documentos de uma coleção que mais se
assemelham a este, basta encontrar aqueles com maior similaridade de cosseno
com $d$. Para tanto, pode-se calcular os valores $\mathid{sim}(d,d_i)$ entre
$d$ e os demais $d_i$ documentos da coleção e os maiores valores indicarão os
documentos mais semelhantes.

Considerando o fato de que \textit{queries}, assim como documentos, são um
conjunto me palavras, elas também podem ser representadas como vetores no
modelo de espaço vetorial. A tabela \ref{tab:queries_mev} apresenta as
consultas $q_1$, $q_2$ e $q_3$ neste espaço. Logo, a similaridade de cosseno
também pode ser utilizada em buscas, considerando que os documentos mais
similares a determinada \textit{query} são os mais relevantes para a mesma
(equação \ref{eq:tfidf_r_sim}).

\begin{equation}
\label{eq:tfidf_r_sim}
  \mathid{R}_{d,q} = \mathid{sim}(d,q)
\end{equation}

\begin{table}[h!]
  \caption{Representação das queries no modelo de espaço vetorial}
  \label{tab:queries_mev}
  \centering
  \small
  \begin{tabular}{| l | c | c | c |}
    \hline
    \multicolumn{4}{|c|}{$\boldsymbol{\tfidf_{t,d}}$}\\
    \hline
    \backslashbox{\textbf{\textit{Termo}}}
                  {\vspace{-0.2cm}\textbf{\textit{Query}}}&
    $\boldsymbol{q_1}$ & $\boldsymbol{q_2}$ & $\boldsymbol{q_3}$\\
    \hline
    moren & $0.12$ & $0.12$ & $0.12$ \\
    \hline
    roup & $0$ & $0$ & $0$ \\
    \hline
    don & $0$ & $0$ & $0.6$ \\
    \hline
    crav & $0$ & $0$ & $0$ \\
    \hline
    canel & $0$ & $0$ & $0$ \\
    \hline
    olh & $0$ & $0$ & $0$ \\
    \hline
    ros & $0$ & $0$ & $0.42$ \\
    \hline
    bob & $0$ & $0.9$ & $0$ \\
    \hline
  \end{tabular}
\end{table}

%\begin{table}[h!]
%  \caption{Relevância por similaridade de cosseno}
%  \label{tab:queries_cosseno}
%  \centering
%  \small
%  \begin{tabular}{| c | c | c | c |}
%    \hline
%    \multicolumn{4}{|c|}{$\boldsymbol{\mathit{sim}(d,q)}$}\\
%    \hline
%    \backslashbox{\textbf{\textit{Doc}}}
%                  {\vspace{-0.2cm}\textbf{\textit{Query}}}&
%    \textbf{$q_1$}&\textbf{$q_2$}&\textbf{$q_3$}\\
%    \hline
%    (1) & $0$ & $0$ & $0$ \\
%    \hline
%    (2) & $0$ & $0$ & $0$ \\
%    \hline
%    (3) & $0$ & $0$ & $0$ \\
%    \hline
%    (4) & $0$ & $0$ & $0$ \\
%    \hline
%    (5) & $0$ & $0$ & $0$ \\
%    \hline
%    (6) & $0$ & $0$ & $0$ \\
%    \hline
%    (7) & $0$ & $0$ & $0$ \\
%    \hline
%    (8) & $0$ & $0$ & $0$ \\
%    \hline
%  \end{tabular}
%\end{table}

\subsection{Okapi BM25}

\textit{Okapi BM25} é o modelo probabilístico considerado estado da arte em
recuperação da informação \cite{Perez:09}. É amplamente utilizado no
desenvolvimento de ferramentas de busca para os mais diversos domínios de
aplicação. Tornou-se bastante popular em virtude de seu destaque nas avaliações
do TREC\footnote{O \textit{Text Retrieval Conference (TREC)} é uma conferência
anual realizada pelo \textit{U.S. National Institute of Standards and
Technology (NIST)} que promove uma ampla competição em recuperação da
informação de grandes coleções de texto com o intuito de incentivar pesquisas
na área.}, sendo apontado como o melhor entre os esquemas de peso
probabilísticos conhecidos \cite{Betts:07}. A título de ilustração,
Xapian\footnote{\url{http://xapian.org/}} e
Lucene\footnote{\url{http://lucene.apache.org/}}, bibliotecas livres para
construção de motores de busca, são projetos de grande destaque na
comunidade que utilizam o \textit{BM25} como medida de pesos. O nome
\textit{Okapi} advém do primeiro sistema no qual foi implementado, denominado
\textit{City Okapi}, enquanto \textit{BM} se refere à família de esquemas
\textit{Best Match}.

Embora seja comumente apresentado num contexto de busca em texto, o esquema não
é específico para este domínio e pode ser usado na estimativa de relevância
para qualquer tipo de recuperação de informação. A realização de consultas
depende da descrição de itens e necessidades dos usuários, no entanto o modelo
em princípio é compatível com inúmeras possibilidades de unidades descritivas
\cite{Jones:00}. Todavia, formalmente o modelo se refere a descrições de
documentos como $D$ e de consultas como $Q$, ambas podendo ser decompostas em
unidades menores. Cada componente é um atributo $A_i$, que pode assumir
valores do domínio $\{\mathit{presente, ausente}\}$ ou valores inteiros não
negativos, representando o número de ocorrências do termo no documento ou na
\textit{query}.

A busca no modelo probabilístico fundamenta-se no \textit{Princípio de
Ordenação por Probabilidade}, segundo o qual a maior eficácia de uma consulta
num conjunto de dados é obtida quando os documentos recuperados são ordenados
de maneira decrescente pela probabilidade de relevância em tal base de dados.
\cite{Robertson:77}. No entanto, o ponto chave do Princípio é que a
probabilidade de relevância não é o fim em si mesma, mas um meio de ordenar os
documentos para apresentação ao usuário. Portanto, qualquer transformação
desta probabilidade pode ser usada, desde que preserve a ordenação pela
relevância \cite{Jones:00}.

%\newpage
\vspace{0.3cm}
\hspace{-1.4cm}
\textbf{Modelo formal}

Dado um documento descrito por $D$ e uma \textit{query} $Q$, o modelo considera
a ocorrência de dois eventos: $L = \{D \text{  é relevante para  } Q\}$ e
$\overline L = \{D \text{  não é relevante para  } Q\}$. Para que a
ordenação por relevância seja possível, calcula-se para cada documento a
probabilidade $P(L|D)$. A aplicação do teorema de Bayes permite que $P(L|D)$
seja expressa em função de $P(D|L)$ (equação \ref{eq:bayes-okapi}).

\begin{equation}
\label{eq:bayes-okapi}
  P(L|D) = \frac{P(D|L)P(L)}{P(D)}
\end{equation}

Para evitar a expansão de $P(D)$, a chance de $(L|D)$ é utilizada ao invés da
probabilidade. Na verdade, o logaritmo da chance é aplicado (equação
\ref{eq:log-odd}), considerando que esta é uma transformação que satisfaz o
Princípio de Ordenação \cite{Jones:00}. Ademais, dado que o último termo da
fórmula é igual para todos os documentos, ele pode ser desconsiderado sem que
isso altere a ordenação dos documentos. Desta forma, a equação \ref{eq:rprim}
descreve uma pontuação por relevância referenciada como primária
($\mathid{R-PRIM_D}$).

\begin{eqnarray}
  \log \frac{P(L|D)}{P(\overline{L}|D)} & = &
  \log \frac{P(D|L)P(L)}{P(D|\overline{L})P(\overline{L})} \nonumber \\
  &=& \log \frac{P(D|L)}{P(D|\overline{L})} + \cancel{\log \frac{P(L)}
                                                           {P(\overline{L})}}
  \label{eq:log-odd} \\
  \mathid{R-PRIM_D} & = & \log \frac{P(D|L)}{P(D|\overline{L})}
  \label{eq:rprim}
\end{eqnarray}

Assim como o modelo de classificação \textit{Bayes} ingênuo, o \textit{BM25}
assume que os atributos dos documentos são estatisticamente independentes de
todos os outros. \cite{Jones:00} justifica a suposição de independência de
atributos pelos seguintes argumentos:
\begin{enumerate}
  \item Facilita o desenvolvimento formal e expressão do modelo;
  \item Torna a instanciação do modelo tratável computacionalmente;
  \item Ainda assim permite estratégias de indexação e busca com melhor
    performance do que estratégias rudimentares, como o simples casamento de
    padrões aplicados a termos da \textit{query} no documento.
\end{enumerate}

De acordo com a suposição de independência, a probabilidade de um documento
pode ser trivialmente derivada a partir das probabilidade de seus atributos.
Logo, $\mathid{R-PRIM_D}$ poderia ser estimado como um somatório de
probabilidades, cada uma relacionada a cada atributo da descrição $D$ (equação
\ref{eq:rprim-atributos}).

\begin{eqnarray}
\label{eq:rprim-atributos}
  \mathid{R-PRIM_D} &=& \log \prod_{i} \frac{P(A_i=a_i|L)}
                                          {P(A_1=a_1|\overline{L})} \nonumber \\
                            &=& \sum_{i} \log \frac{P(A_i=a_i|L)}
                                          {P(A_1=a_1|\overline{L})}
\end{eqnarray}

No entanto, a fórmula \ref{eq:rprim-atributos} pressupõe a consideração de um
componente para cada valor do atributo, por exemplo, para presença de um termo
assim como para sua ausência. Uma alternativa mais natural seria considerar
apenas valores para a presença, contabilizando a ausência como um
\textit{zero} natural. Desta forma, é subtraído da pontuação de cada
documento o componente relativo a cada valor de atributo zerado (fórmula
\ref{eq:rbasic}).

\begin{eqnarray}
  \mathid{R-BASIC_D} &=& {\mathid R-PRIM_D} - \sum_{i} \log \frac{P(A_i=0|L)}
                                 {P(A_1=0|\overline{L})} \nonumber \\
  & = & \sum_{i} \Big (\log\frac{P(A_i=a_i|L)}{P(A_1=a_1|\overline{L})}
                       -\log\frac{P(A_i=0|L)}{P(A_1=0|\overline{L})}
                 \Big ) \nonumber \\
  & = & \sum_{i} \log\frac{P(A_i=a_i|L)P(A_1=0|\overline{L})}
                          {P(A_1=a_1|\overline{L})P(A_i=0|L)}
  \label{eq:rbasic}
\end{eqnarray}

Considerando $W_i$ como um peso para cada termo $t_i$ do documento (equação
\ref{eq:peso_termo}), $\mathid{R-BASIC_D}$ pode ser então reescrito em função
deste peso, como na equação \ref{eq:rbasic_peso_termo}.

\begin{equation}
\label{eq:peso_termo}
  W_i = \displaystyle \log\frac{P(A_i=a_i|L)P(A_1=0|\overline{L})}
                     {P(A_1=a_1|\overline{L})P(A_i=0|L)}
\end{equation}

\begin{equation}
\label{eq:rbasic_peso_termo}
\hspace{-2.5cm}
  \mathid{R-BASIC_D} = \sum_{i} W_i
\end{equation}

No caso em que os atributos $A_i$ restringem-se a exprimir a presença ou
ausência do termo $t_i$ (atributos binários), pode-se dizer que {\small$P(A_1=0
|L)=1-P(A_i=1|L)$}, o mesmo vale para $\overline L$. Portanto, considerando que
$p_i = P(t_i \text{ ocorre }|L)$ e $\overline p_i = P(t_i \text{ ocorre }|
\overline L)$, a fórmula \ref{eq:peso_termo} pode ser usada como um peso para
presença de termos. A pontuação de relevância para um documento seria então a
soma dos pesos $w_i$ dos termos da \textit{query} presentes no documento.

\begin{equation}
\label{eq:peso_termo_binario}
  w_i = \log \frac{p_i(1-\overline{p_i})}{\overline{p_i}(1-p)}
\end{equation}

A seguir será apresentada a interpretação do modelo formal a partir de
informações disponíveis sobre a coleção de documentos, com o intuito de
definir funções de peso eficazes para a ordenação por relevância.

\vspace{0.3cm} \hspace{-1.4cm}
\textbf{Incidência dos termos e atestação de relevância}

A incidência dos termos nos documentos da coleção é uma informação que pode ser
facilmente coletada e pode ser utilizada como parâmetro no cálculo da
probabilidade de relevância. O popular $idf_t$ (equação \ref{eq:idf}) é uma
medida plausível e, apesar de ter sido proposta baseada apenas na frequência
de incidência dos termos, também pode ser derivada da equação
\ref{eq:peso_termo_binario} \cite{Jones:00}.

No entanto, apenas a incidência dos termos é uma base fraca para a estimativa
de probabilidades de relevância. As estimativas podem ser refinadas através
da consideração de dados acerca da real relevância ou irrelevância de
documentos, obtidos por exemplo através de procedimentos de \textit{atestação
de relevância}\footnote{Mecanismo através do qual o usuário avalia o resultado
da consulta, marcando os itens retornados como relevantes ou irrelevantes -- no
idioma inglês, referenciado como \textit{relevance feedback}.}.

A tabela de contingência da incidência dos termos é apresentada na tabela
\ref{tab:bm25_contingencia}. $N$ representa o número total de documentos da
coleção, enquanto $n$ representa o número de documentos nos quais o termo $t$
da \textit{query} ocorre. Analogamente, $R$ é a quantidade de documentos
relevantes para a consulta e $r$ a quantidade de documentos relevantes
nos quais o termo ocorre.

\begin{table}[h!]
\caption{Tabela de contingência da incidência dos termos}
\label{tab:bm25_contingencia}
\centering
\begin{tabular}{|l|c|c|c|}
\hline
                      & Relevante & Irrelevante & Incidência na coleção\\
\hline
$t$ ocorre            & $r$         &   $n-r$       & $n$   \\
\hline
$t$ não ocorre        & $R-r$       &   $N-n-R+r$   & $N-n$ \\
\hline
total de documentos   & $R$         &   $N-R$       & $N$   \\
\hline
\end{tabular}
\end{table}

Portanto, a probabilidade de um termo $t$ ocorrer num documento, dado que
este é relevante para a \textit{query} é $p = \frac{r}{R}$. Analogamente,
dado que o documento não é relevante, $\overline p = \frac{n-r}{N-R}$. Desta
forma, a equação \ref{eq:peso_termo_binario} pode ser redefinida como a fórmula
\ref{eq:peso_termo_contingencia}, que exprime o logaritmo da razão de chances
de um termo ocorrer em documentos relevantes e irrelevantes.

\begin{equation}
\label{eq:peso_termo_contingencia}
  w = \log \frac{r(N-n-R+r)}{(R-r)(n-r)}
\end{equation}

Por fim, o fator de correção $0.5$ é acrescido a cada termo central da fórmula
para evitar que o peso seja zerado quando algum destes termos for
$\mathit{zero}$.

\begin{equation}
\label{eq:RW}
  \rW = \log \frac{(r+0.5)(N-n-R+r+0.5)}
                               {(R-r+0.5)(n-r+0.5)}
\end{equation}

Se não houver informações provenientes da atestação de relevância, o $\idf_t$
clássico pode ser utilizado (equação \ref{eq:idf}), ou ainda, uma variação de
$\rW$ a partir do estabelecimento de que $R=r=0$
(equação \ref{eq:RW_simples}).

\begin{equation}
\label{eq:RW_simples}
  \rW = \log \frac{N-n+0.5}{n+0.5}
\end{equation}

\vspace{0.3cm} \hspace{-1.4cm}
\textbf{Distribuição dos termos nos documentos}

A incidência dos termos na coleção distingue os documentos com relação aos
termos da \textit{query} no que diz respeito apenas à ocorrência ou ausência
dos mesmos. Usando apenas esta medida não é possível portanto diferenciar
dois documentos em relação a um termo se o mesmo ocorre em ambos. No caso
em que dados de frequência dos termos são providos nas descrições dos
documentos, esta informação pode contribuir para a estimativa de relevância do
de um documento.

Assume-se que cada termo é associado a um conceito, ao qual um determinado
documento pode estar relacionado ou não. Logo, para cada conceito existe um
conjunto de documentos que dizem respeito a ele e outro conjunto que não
(complementar ao primeiro). A frequência de um termo em um documento
caracteriza sua ocorrência quantitativamente, porém, uma frequência maior que
$\mathit{zero}$ não significa que o documento esteja necessariamente
relacionado com conceito do termo. Diante da impossibilidade de se prever esta
relação conceitual, considera-se a distribuição de frequências dos termos nos
documentos como uma mistura de duas distribuições, uma para cada um dos
conjuntos \cite{Jones:00}.

Essa distribuição pode ser entendida como originada num modelo de geração de
texto: o autor se depara com as posições de palavras nos documentos e
escolhe termos para ocupar tais posições. Se a probabilidade de escolha de
cada termo for fixa e todos os documentos forem de igual comprimento,
caracteriza-se uma distribuição de \textit{Poisson} para frequências dos termos
nos documentos. Assume-se probabilidades diferentes para o conjunto de
documentos relacionados ao conceito do termo e para o conjunto dos que não são
-- esta é a razão para a mistura de duas distribuições \cite{Jones:00}.

A derivação deste componente do peso é mais extensa e por esta razão foi
omitida neste texto. A fórmula resultante é complexa, no entanto
\cite{Robertson:94} examina o comportamento da mesma e propõe uma aproximação
que apresenta comportamento similar à original, expressa pela equação
\ref{eq:RD}.

\begin{equation}
\label{eq:RD}
  \rD = \frac{\tf_{t,D}(k_1+1)}{k_1+\tf_{t,D}}
\end{equation}

A constante $k_1$ determina o quanto o peso do documento em relação ao termo
deve ser afetado por um acréscimo no valor de $\tf_{t,D}$. Se $k_1=0$, então
$\rD = 1$, e $\tf_{t,D}$ não interfere no peso final. Para valores altos de
$k_1$, o peso passa a ter um crescimento linear com relação a $\tf_{t,D}$. De
acordo com experimentos do TREC, valores entre $1.2$ e $2$ são os mais
indicados, visto que implicam numa interferência altamente não linear de
$\tf_{t,D}$, ou seja, após 3 ou 4 ocorrências o impacto de uma ocorrência
adicional é mínimo \cite{Jones:00}.

No entanto, a modelagem através distribuições de \textit{Poisson} assume que
todos os documentos têm mesmo comprimento, o que não acontece na prática.
Porém, uma interpretação ligeiramente estendida do modelo permite a
consideração de documentos com comprimentos distintos.

Os comprimentos dos documentos da coleção podem variar por inúmeros motivos.
Todavia, nesta nova interpretação assume-se que quando dois documentos acerca
do mesmo conceito têm tamanhos distintos, a razão é simplesmente que um é mais
verboso que o outro. Em outras palavras, considera-se que a recorrência de
palavras deve-se sempre à repetição, ao invés por exemplo da melhor elaboração
do tema. Partindo desta suposição, é apropriado estender o modelo normalizando
o valor de $\tf_{t,D}$ em função do comprimento do documento (equação
\ref{eq:RD_nl}).

\begin{equation}
  \label{eq:RD_nl}
  \rD =  \frac{\frac{\tf_{t,D}}{\mathid{NL}}(k_1+1)}
              {k_1+\frac{\tf_{t,D}}{\mathid{NL}}} =
         \frac{\tf_{t,D}(k_1+1)}{k_1*\mathid{NL}+\tf_{t,D}}
\end{equation}

Dado que o comprimento dos documentos pode ser medido de diversas formas
(quantidade de palavras, caracteres e \textit{bytes}, considerando ou não
\textit{stop words}), considera-se a medida uniformizada para normalização,
obtida pela razão entre o comprimento dos documentos e o comprimento médio dos
documentos ($\frac{l_d}{l_{\mathid{avg}}}$). Ademais, uma normalização simples
resultaria na mesma pontuação para um documento de comprimento $l$ no qual o
termo ocorre $tf$ vezes e para outro de comprimento $2l$ que contém $2tf$
ocorrências do termo. Este comportamento pode ser indesejável por exemplo
quando se considera que a recorrência de palavras está geralmente associada ao
aprofundamento do conceito, ao invés de mera repetição.

A fórmula proposta \eqref{eq:nl} permite que a normalização ocorra em
diferentes graus, de acordo com o ajuste do parâmetro constante $b$ que assume
valores no intervalo $[0,1]$. Se a configuração for $b=1$, a normalização tem
efeito completo (equivalente ao esquema \textit{BM11}). Valores menores reduzem
este efeito, e se $b=0$ o comprimento do documento não afeta a pontuação final,
(como no modelo \textit{BM15}).

\begin{equation}
  \label{eq:nl}
  \mathid{NL} = ((1-b)+b\frac{l_d}{l_{\mathid{avg}}})
\end{equation}

\begin{equation}
\label{eq:RD_l}
  \rD = \frac{\tf_{t,D}(k_1+1)}
                         {k_1((1-b)+b\frac{l_d}{l_{\mathid{avg}}})+\tf_{t,D}}
\end{equation}

\vspace{0.3cm} \hspace{-1.4cm}
\textbf{Consultas longas}

Em situações onde as consultas podem ser descritas por \textit{queries}
longas, por exemplo, o caso em que um documento pode ser utilizado como
base para a consulta, a consideração da frequência do termo na \textit{query}
pode ser mais um fator contribuinte para a estimativa de relevância. O
componente $\rQ$ também é derivado a partir da modelagem em distribuições de
\textit{Poisson}, porém aplicadas ao conjunto de \textit{queries} ao invés do
conjunto de documentos. O resultado é um peso semelhante ao $\rD$, porém com
parâmetros constantes próprios (equação \ref{eq:RQ}). Todavia, para o caso de
\textit{queries} com poucos termos, este componente do peso deve ser
desconsiderado.

\begin{equation}
\label{eq:RQ}
  \rQ = \frac{(k_3+1)\mathid{qtf}_{t,Q}}{k_3+\mathid{qtf}_{t,Q}}
\end{equation}

\newpage
%\vspace{0.3cm}
\hspace{-1.4cm}
\textbf{Estimativa de relevância}

Finalmente, a relevância de um documento $D$ para uma consulta $Q$ pode ser
obtida pelo somatório dos pesos dos termos da \textit{query} com relação a $D$.
O peso de cada termo é obtido pelo produto dos componentes apresentados
anteriormente, como indica a equação \ref{eq:bm25}.

\begin{equation}
\label{eq:bm25}
\mathid{R}_{D,Q} = \sum_{t \in Q} \rW \cdot \rD \cdot \rQ
\end{equation}

% ver http://en.wikipedia.org/wiki/Neighbourhood_components_analysis

\subsection{Apriori} \label{sec:apriori}

A mineração de Dados, também referenciada como descoberta de conhecimento em
bases de dados, é a área da ciência da computação destinada à descoberta de
correlações e padrões frequentes num conjunto de dados. Informações extraídas
de uma base de dados de transações de venda, por exemplo, têm alto valor para
organizações que pretendem realizar processos de \textit{marketing} guiados por
informação -- modelo denominado, em inglês, \textit{market basket analysis}.
Outros domínios de aplicação que também utilizam técnicas de mineração são:
detecção de intrusão através da análise de \textit{logs} de sistemas
computacionais, pesquisas na área de saúde sobre a correlação entre doenças,
sequenciamento de DNA etc \cite{Hegland:03}.

Os padrões frequentes podem ser descritos por conjuntos de itens que ocorrem
simultaneamente ou por implicações na forma $X \Rightarrow Y$, denominadas de
\textit{regras de associação}, sendo $X$ e $Y$ conjuntos de itens disjuntos ($X
\cap Y = \emptyset$). \textit{Suporte} e \textit{confiança} são duas métricas
para quantificar a força dos padrões de acordo com a sua representatividade no
banco de dados de transações. O suporte de um conjunto de itens é a frequência
com a qual ele ocorre numa base de dados. Para uma regra de associação $X
\Rightarrow Y$, mede-se o suporte do conjunto de itens $X \cup Y$. A confiança
de uma regra é medida pela frequência de $Y$ nos registros que contém $X$,
representando o grau de co-ocorrência de $X$ e $Y$.

O \textit{Apriori} é um algoritmo clássico para mineração de regras de
associação sustentadas por medidas mínimas de suporte e confiança numa base de
dados. Este problema é comumente decomposto em dois sub-problemas:

\begin{enumerate}[(1)]
  \item Identificação de todos os conjuntos de itens que extrapolam um valor de
    suporte mínimo na base de dados (denominados de \textit{conjuntos
    frequentes}).
  \item Produção de regras de associação a partir dos conjuntos frequentes,
    selecionando apenas as que satisfazem a condição de confiança mínima.
    Visto que as regras são partições binárias de conjuntos de itens, uma
    solução trivial para este problema é: para cada subconjunto $S$ de
    um conjunto frequente $F$, gerar a regra $S \Rightarrow F - S$ e testar
    seu valor de confiança.
\end{enumerate}

O \textit{Apriori} foi o primeiro algoritmo a tratar do sub-problema
\textit{(1)}, que de fato é o mais desafiador, de forma mais eficiente. Uma
solução ingênua para tal problema seria: listar todos os conjuntos candidatos
(conjunto das partes do universo de itens) e selecionar os conjuntos frequentes
a partir do cálculo de suporte para cada um. No entanto, esta é uma estratégia
extremamente custosa visto que o conjunto das partes de um conjunto com $n$
elementos contém $2^n$ subconjuntos, inviabilizando o cálculo para domínios de
aplicação com um universo de itens grande \cite{Hegland:03}. A figura
\ref{fig:diagrama_hasse} ilustra através de um diagrama de \emph{Hasse} o
conjunto das partes do universo de itens $U=\{a,b,c\}$.

\begin{figure}[ht]
\centering
\includegraphics[width=.4\textwidth]{Figures/diagrama_hasse.pdf}
\caption{Conjunto das partes ilustrado por um diagrama de \emph{Hasse}}
\label{fig:diagrama_hasse}
\end{figure}

A inovação do \textit{Apriori} sobre a abordagem ingênua é a redução da
quantidade de conjuntos candidatos pelo descarte de certos conjuntos que
comprovadamente não são conjuntos frequentes. Desta forma o algoritmo
consegue detectar todos os conjuntos frequentes sem a necessidade de calcular o
suporte para todos os $2^n$ subconjuntos possíveis.

A descoberta de conjuntos frequentes acontece por níveis, como uma busca em
largura no diagrama de \emph{Hasse} começando pelos conjuntos unitários. Ao
invés de gerar os conjuntos candidatos a partir da base de dados, a cada nível
da busca é feita uma combinação dos elementos para gerar os candidatos do nível
seguinte. Neste ponto a solução se beneficia do seguinte princípio: qualquer
subconjunto de um conjunto frequente também é um conjunto frequente. Portanto,
só devem participar da nova combinação os elementos que apresentarem um suporte
superior ao limite, pois um conjunto que não é frequente não será jamais
subconjunto de um conjunto frequente \cite{Agrawal:94}.

A figura \ref{fig:diagrama_apriori} ilustra a descoberta dos conjuntos
frequentes em contraposição com o conjunto das partes do conjunto $U =
\{a,b,c,d,e\}$. Neste exemplo, os subconjuntos $\{e\}$, $\{a,b\}$ e $\{b,d\}$
estão destacados por apresentarem suporte inferior ao limite. Consequentemente,
todos os conjuntos dos quais estes são subconjuntos foram desconsiderados como
conjuntos candidatos (nós com fundo cinza na figura). Portanto, apenas os nós
com fundo branco teriam o suporte calculado.

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{Figures/diagrama_apriori.pdf}
\caption{Geração de conjuntos candidatos pelo algoritmo Apriori}
\label{fig:diagrama_apriori}
\end{figure}

%http://www.slidefinder.net/d/data_mining_association_analysis_basic/14431678

A introdução do \textit{Apriori} representou um marco para o desenvolvimento de
soluções para mineração de dados, motivando o surgimento de inúmeras variantes
baseadas no mesmo princípio. Entre elas, surgiram algumas propostas específicas
para situações onde os dados têm características adicionais conhecidas como,
por exemplo, base de dados particionada, dados que satisfazem à determinadas
restrições ou que fazem parte de uma taxonomia conhecida \cite{Hegland:03}.

Apesar de apresentar um processo inovador para geração de regras de associação,
o \textit{Apriori} também apresenta fraquezas, sendo a principal delas a
necessidade de percorrer a base de dados múltiplas vezes para cálculo de
suporte e confiança dos conjuntos de itens. Algumas soluções alternativas
fazem uso de estruturas de dados auxiliares para armazenar informações
extraídas da base de dados numa única passagem, evitando desta forma repetidos
acessos à mesma. Árvores de prefixos, árvores lexicográficas e matrizes
binárias são algumas dessas estruturas \cite{Kotsiantis:06}.

\section{Estratégias de recomendação} \label{sec:estrategias}

Neste trabalho considera-se uma classificação mista dos seguintes autores.
\cite{Burke:02} distingue as diferentes estratégias de recomendação a partir
da fonte de dados de onde é extraído o conhecimento para produzir as
recomendações. \cite{Cazella:10} propõe uma classificação um pouco mais
abrangente, considerando por exemplo a recomendação por reputação dos itens,
que por não oferecer grandes desafios computacionais é omitida por algumas
taxonomias.

\subsection{Reputação dos itens}

Popular entre serviços de venda como livrarias, sites de leilão e
lojas de modo geral, esta estratégia consiste no armazenamento de avaliações
dos produtos escritas por usuários, bem como na apresentação das mesmas no
momento e local apropriado \cite{Cazella:10}. A implementação desta solução é
simples, visto que exige apenas a manutenção dos dados originais, não sendo
necessária análise posterior alguma. No entanto, tem-se como premissa a
imparcialidade dos usuários em suas opiniões, que de fato não pode ser
verificada devido a seu caráter subjetivo e estritamente pessoal. Atualmente
existem serviços especializados em reputação de produtos que não realizam
venda associada, apenas disponibilizam as avaliações. É o caso do
\textit{Internet Movie Database} \footnote{\url{http://www.imdb.com/}},
apresentado na figura \ref{fig:imdb}.

\begin{figure}[h!]
\centering
\fbox{
  \includegraphics{Figures/imdb.pdf}
}
\caption{Avaliação de usuário no IMDb}
\label{fig:imdb}
\end{figure}

\subsection{Recomendação baseada em conteúdo}

Esta abordagem parte do princípio de que os usuários tendem a se interessar por
itens semelhantes aos que eles já se interessaram no passado
\cite{Herlocker:00}. O ponto chave desta estratégia é a caracterização dos
itens, por exemplo, através da identificação de atributos (autores e temas de
livros, por exemplo). A partir dos atributos dos itens, aplica-se técnicas de
recuperação da informação (por exemplo, $\tfidf$ e \textit{BM25}) para
encontrar itens semelhantes ou de classificação (por exemplo, \textit{Bayes
ingênuo} e \textit{K-NN}) para encontrar itens relevantes. Em uma livraria,
sugerir ao cliente outros livros do mesmo autor ou tema de livros previamente
selecionados é uma estratégia amplamente adotada.

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{Figures/rec_conteudo.pdf}
\caption{Cenário de uma recomendação baseada em conteúdo}
\label{fig:rec_conteudo}
\end{figure}

Pelo fato de se apoiar na classificação dos itens, os resultados da
recomendação são prejudicados nos casos em que os atributos não podem ser
identificados de forma automatizada. A superespecialização é outro problema
indicado por \cite{Adomavicius:05}, que diz respeito à abrangência das
recomendações estar limitada a itens similares aos já escolhidos pelos usuários.

\subsection{Recomendação colaborativa}

Esta estratégia não exige o reconhecimento semântico do conteúdo dos itens,
pois é fundamentado na troca de experiências entre indivíduos que possuem
interesses em comum. A figura \ref{fig:rec_colaborativa} ilustra o cenário da
recomendação colaborativa.

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{Figures/rec_colaborativa.pdf}
\caption{Cenário da recomendação colaborativa}
\label{fig:rec_colaborativa}
\end{figure}

A técnica \textit{K-NN} é comumente utilizada neste tipo de solução. Define-se
uma função que representa a proximidade entre os usuários. Com base nesta
medida, a vizinhança de um determinado usuário é composta por outros $k$
usuários que estiverem mais próximos a ele. Porém, ao invés de uma classe ser
extraída da vizinhança, como descrito na seção \ref{sec:knn}, uma recomendação
para o usuário é produzida a partir da análise dos itens que os usuários
vizinhos consideram relevantes. Geralmente os itens que ocorrem com maior
frequência na vizinhança compõem a recomendação.

O problema da superespecialização é superado, visto que a recomendação neste
caso não se baseia no histórico do próprio usuário, portanto pode apresentar
itens totalmente inesperados. Outra contribuição é a possibilidade de formação
de comunidades de usuários pela identificação de interesses semelhantes
\cite{Cazella:10}.

\subsection{Baseada em conhecimento}

Esta estratégia tem como princípio a descoberta de conhecimento a partir da
análise de uma base de dados de transações, que registra a escolha dos usuários
ao longo do tempo. Técnicas de classificação e mineração de dados são
utilizadas para extrair correlações e padrões frequentes no comportamento dos
usuários. Tal abordagem é frequentemente utilizada em recomendações implícitas,
por exemplo, na definição do posicionamento de produtos numa prateleira ou a
realização de propagandas dirigidas \cite{Hegland:03}.

Agrupamento (\textit{clustering}, em inglês) é uma técnica de aprendizado de
máquina não supervisionado. O algoritmo particiona a base de dados de forma a
criar automaticamente grupos que reúnam usuários com comportamentos
semelhantes. Uma das técnicas mais utilizadas é o $k\mhyphen means$, que
consiste basicamente em: (1) seleção de $k$ usuários considerados sementes; (2)
associar cada usuário da base de dados com a semente mais próxima dele; (3)
calcular novos elementos centrais para cada grupo, entre os usuários que o
compõem. O passo 3 é repetido até que não seja mais necessário calcular novos
centróides. Desta forma, um sistema de recomendação poderia sugerir itens de
acordo com as características de cada grupo \cite{Cazella:10}.

Para descoberta de regras de associação, as técnicas mais utilizadas são
variações do algoritmos Apriori, apresentado na seção \ref{sec:apriori}
\cite{Kotsiantis:06}. Dado um conjunto de associações, a recomendação para
determinado usuário é produzida de acordo com as regras satisfeitas pelo
conjunto de itens que ele já tenha selecionado. Por exemplo, a regra ${A,B,C}
\Rightarrow {D}$ seria satisfeita por usuários que possuem os itens $A$, $B$ e
$C$, resultando na indicação do item $D$: \textit{``Clientes que compraram os
itens A, B e C também compraram o item D''}. Um exemplo de recomendação por
associação é encontrado na loja virtual da empresa \textit{Amazon}\footnote{\url{http://www.amazon.com/}} (figura \ref{fig:amazon}).

\begin{figure}[h!]
\centering
\fbox{
  \includegraphics{Figures/amazon.pdf}
}
\caption{Recomendação por associação na Amazon}
\label{fig:amazon}
\end{figure}

\subsection{Baseada em dados demográficos}

A estratégia demográfica fundamenta-se na composição de perfis de usuários e
identificação de nichos demográficos para produção de recomendações. Os dados
pessoais geralmente são coletados de forma explícita, através de um cadastro
do usuário, e podem englobar informações como idade, sexo, profissão e áreas de
interesse. Dados demográficos, no entanto, geralmente são utilizados em
combinação com outras fontes de dados e técnicas diversas, como parte de uma
estratégia de recomendação híbrida.

\subsection{Estratégia híbrida} \label{sec:estrategias_hibrida}

Sistemas de recomendação híbridos combinam duas ou mais estratégias, com o
intuito de obter melhor performance do que a que as estratégias oferecem
individualmente. A tabela \ref{tab:metodos_hibridizacao} apresenta as
principais técnicas de hibridização, segundo \cite{Burke:02}.

\begin{table}[h!]
\caption{Métodos de hibridização}
\label{tab:metodos_hibridizacao}
\small
\begin{tabularx}{\textwidth}{| l | X |}
\hline
\normalsize{\textbf{\textit{Método}}} &
\normalsize{\textbf{\textit{Descrição}}} \\
\hline
Ponderação & Pontuações de relevância oriundas de diversas técnicas de
             recomendação são combinadas para compor uma única recomendação. \\
\hline
Revezamento & O sistema reveza entre técnicas de recomendação diversas, de
              acordo com a situação do momento. \\
\hline
Combinação & Recomendações oriundas de diversos recomendadores diferentes são
             apresentados de uma só vez. \\
\hline
Combinação de atributo & Um algoritmo de recomendação único coleta atributos
                         de diferentes bases de dados para recomendação. \\
\hline
Cascata & Um recomendador refina a recomendação produzida por outro. \\
\hline
Acréscimo de atributo & O resultado de uma técnica é usado como atributo de
                        entrada para outra. \\
\hline
Meta-nível & O modelo que um recomendador ``aprendeu'' é usado como entrada
             para o outro. \\
\hline
\end{tabularx}
\end{table}

\section{Avaliação de sistemas de recomendação} \label{sec:avaliacao}

A avaliação de sistemas de recomendação não é uma tarefa trivial,
principalmente porque não há consenso sobre quais atributos devem ser
observados e quais métricas devem ser adotadas para cada atributo
\cite{Herlocker:04}. Ademais, diferentes estratégias podem funcionar melhor
ou pior de acordo com o domínio da aplicação e as propriedades dos dados.
Por exemplo, algoritmos projetados especificamente para conjuntos de dados com
um número muito maior de usuários do que de itens podem se mostrar
inapropriados em domínios onde há muito mais itens do que usuários.
Recomenda-se então que o processo de avaliação tenha início com a compreensão
das ações para as quais o sistema foi projetado (ver seção \ref{sec:acoes}),
como guia para as decisões metodológicas ao longo dos experimentos.

\subsection{Seleção dos dados}

A escolha do conjunto de dados adequado é fator chave para uma investigação
consistente. Neste aspecto, as avaliações de recomendadores podem ser
caracterizadas como (a) análises \textit{offline}, que utilizam bases de dados
previamente coletadas e (b) experimentos ``ao vivo'', realizados diretamente
com usuários, seja num ambiente controlado (laboratório) ou em campo
\cite{Herlocker:04}.

Análises \textit{offline} geralmente são objetivas, com foco na acurácia das
predições e performance das soluções \cite{Vozalis:03}. Inicialmente os dados
são particionados em porções de treinamento e de testes. Utiliza-se como base
os dados de treinamento para prever recomendações para itens da porção de
testes. Em seguida é feita a análise comparativa entre os resultados obtidos
e os esperados. Algumas métricas comumente utilizadas na fase de análise serão
apresentadas na seção \ref{sec:metricas}. No entanto, tais análises são
prejudicadas em conjuntos de dados esparsos. Não se pode, por exemplo, avaliar
a exatidão da recomendação de um item para um usuário se não existe uma
avaliação prévia do usuário para tal item.

Por outro lado, nos experimentos ``ao vivo'' os recomendadores são
disponibilizados para uma comunidade de usuários, cujas avaliações são
coletadas na medida em que são produzidas. Neste caso, além de análises
objetivas como a acurácia e performance das soluções, pode-se avaliar fatores
comportamentais como a performance, participação e satisfação dos usuários.
A esparsidade dos dados tem efeito menor neste tipo de experimento, visto
que o usuário está disponível para avaliar se os itens recomendados são ou
não relevantes.

Quando não existem dados previamente disponíveis ou quando não são adequados
para o domínio ou a ação principal do sistema a ser avaliado, pode-se ainda
optar pelo uso de dados sintéticos. O uso de dados artificiais é aceitável
em fases preliminares de testes, porém, tecer conclusões comparativas é
arriscado visto que os dados produzidos podem se ajustar melhor para uma
estratégia do que para outras \cite{Herlocker:04}.

\section{Métricas} \label{sec:metricas}

A tabela \ref{tab:metricas} apresenta métricas utilizadas para avaliação de
sistemas de recomendação.

As métricas de acurácia medem o quanto as estimativas de relevância previstas
pelo sistema se aproximam da real. Acurácia de classificação está relacionada
com a frequência com a qual o sistema faz classificações corretas acerca da
relevância dos itens, enquanto que a acurácia de predição pondera as
diferenças entre as pontuações de relevância prevista e a real.

Além de medidas de acurácia, são apresentados outras métricas para mensurar
qualidades que proporcionam maior grau de satisfação do usuário ao utilizar um
sistema de recomendação.

\begin{sidewaystable}
\caption{Métricas para avaliação de sistemas recomendadores}
\label{tab:metricas}
\newcommand\T{\rule{0pt}{3.0ex}}
\newcommand\B{\rule[-1.8ex]{0pt}{0pt}}
\begin{tabularx}{\textwidth}{| c | X | c | c |}
\hline
\textbf{\textit{Métrica}} & \textbf{\textit{Descrição}}
  & \textbf{\textit{Fórmula}}  & \textbf{\textit{Categoria}} \\
\hline
\T Precisão & Proporção de itens relevantes entre os selecionados
  & \multirow{2}{*}{$P = \frac{N_{\text{relevantes\ selecionados}}}
                              {N_{\text{selecionados}}}$}
  & \multirow{7}{*}{Acurácia de classificação} \\
  & como tal \B & & \\
\cline{1-3}
\T Recuperação & Proporção de itens selecionados entre todos os
  & \multirow{2}{*}{$R = \frac{N_{\text{relevantes\ selecionados}}}
                              {N_{\text{relevantes}}}$} & \\
  & relevantes \B & & \\
\cline{1-3}
\T Medida $F_1$ & Combinação de $P$ e $R$ numa mesma medida
  & \T\B $F_1 = \frac{2PR}{P+R}$ & \\
\cline{1-3}
\T Curva \textit{ROC} & Mede o poder de distinção entre itens relevantes e
  & \scriptsize{Análise gráfica}& \\
  & irrelevantes \B & & \\
\hline
\T Erro absoluto médio & Desvio absoluto médio  entre pontuações previstas e
 & \multirow{2}{*}{$|\overline E|=\frac{\sum_{i=1}^N |p_i-r_i|}{N} $}
 & \multirow{4}{*}{Acurácia de predição} \\
 \textit{(MAE)} & reais \B & & \\
\cline{1-3}
\T Erro quadrático médio & Desvio quadrático médio entre pontuações previstas e
  & \multirow{2}{*}{$|\overline E|=\frac{\sum_{i=1}^N |p_i-r_i|^2}{N}$ }& \\
  & reais \B & & \\
\hline
\T Cobertura & Proporção de itens passíveis de serem recomendados
  & \multirow{2}{*}{$R = \frac{N_{\text{passíveis de recomendação}}}{N}$}
  & \multirow{5}{*}{Além de acurácia} \\
  & entre todos os disponíveis \B & & \\
\cline{1-3}
\T Curva de aprendizado & Taxa de aprendizado dos algoritmos na análise dos
  & \multirow{2}{*}{$A = \frac{\Delta_\text{acurácia}}{\Delta_T}$} & \\
  & dados de exemplo \B & & \\
\cline{1-3}
\T Novidade e surpresa & Qualidade do sistema de produzir recomendações
  & \scriptsize{Avaliada pelo usuário} & \\
  & não óbvias \B & & \\
\hline
\end{tabularx}
\end{sidewaystable}

\newpage
